{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933e941c",
   "metadata": {},
   "source": [
    "# A Level-2 Sea Ice Drift (SID) algorithm for CIMR\n",
    "\n",
    "This notebook implements a prototype for a Level-2 SIED algorithm for the CIMR mission.\n",
    "\n",
    "We refer to the corresponding [ATBD](https://cimr-algos.github.io/SeaIceDrift_ATBD/intro.html) and especially the [Baseline Algorithm Definition](https://cimr-algos.github.io/SeaIceDrift_ATBD/baseline_algorithm_definition.html#baseline-algorithm-definition).\n",
    "\n",
    "In particular, the figure below illustrates the overall concept of the processing:\n",
    "<img src=\"https://cimr-algos.github.io/SeaIceDrift_ATBD/_images/CIMR_L2_Sea_Ice_Drift_Flow_Diagram.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987813ed",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Imports and general settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c54c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a41e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "# Getting the path of the notebook (NOTE: not totally safe)\n",
    "# The paths assume that there is an umbrella CIMR directory (of any name) containing SeaIceDrift_ATBD_v2/ ,\n",
    "# the CIMR Tools/ directory, and a directory data/L1B/ containing the L1B data, and data/conc/ containing\n",
    "# a concentration file\n",
    "import os\n",
    "cpath = os.path.join(os.getcwd(), '../..')\n",
    "algpath = os.path.join(cpath, 'SeaIceDrift_ATBD_v2/algorithm/src_sied')\n",
    "toolpath = os.path.join(cpath, 'Tools')\n",
    "l1bpath = os.path.join(cpath, 'data/L1B')\n",
    "\n",
    "# Making a directory structure needed for processing\n",
    "concpath = os.path.join(cpath, 'data/conc')\n",
    "if not os.path.isdir(concpath):\n",
    "    os.makedirs(concpath)\n",
    "icemaskpath = os.path.join(cpath, 'data/icemask')\n",
    "if not os.path.isdir(icemaskpath):\n",
    "    os.makedirs(icemaskpath)\n",
    "swathpath = os.path.join(cpath, 'data/swaths')\n",
    "if not os.path.isdir(swathpath):\n",
    "    os.makedirs(swathpath)\n",
    "procpath = os.path.join(cpath, 'data/processing')\n",
    "if not os.path.isdir(procpath):\n",
    "    os.makedirs(procpath)\n",
    "driftpath = os.path.join(cpath, 'data/icedrift')\n",
    "if not os.path.isdir(driftpath):\n",
    "    os.makedirs(driftpath)\n",
    "logpath = os.path.join(cpath, 'data/logs')\n",
    "if not os.path.isdir(logpath):\n",
    "    os.makedirs(logpath)\n",
    "figpath = os.path.join(cpath, 'data/figs')\n",
    "if not os.path.isdir(figpath):\n",
    "    os.makedirs(figpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b5272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from importlib import reload\n",
    "import sys\n",
    "import shutil\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "import matplotlib.cm as cm\n",
    "import cmocean\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from pyresample import parse_area_file\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Local modules contain software code that implement the SIED algorithm\n",
    "if algpath not in sys.path:\n",
    "    sys.path.insert(0, algpath)\n",
    "from icedrift_wrapper import icedrift_wrapper\n",
    "from process_ice_mask import process_ice_mask\n",
    "from cp_and_date_change_iceconc import cp_and_date_change_iceconc\n",
    "\n",
    "# prototype re-gridding toolbox to handle the L1B input\n",
    "if toolpath not in sys.path:\n",
    "    sys.path.insert(0, toolpath)\n",
    "from tools import io_handler as io\n",
    "from tools import collocation as coll\n",
    "from tools import l2_format as l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a828b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rc('xtick', labelsize=10) \n",
    "matplotlib.rc('ytick', labelsize=10) \n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "matplotlib.rcParams.update({'axes.labelsize': 12})\n",
    "\n",
    "font = {'family' : 'sans',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 12}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "cmap = cm.viridis\n",
    "cmapland = matplotlib.colors.ListedColormap(['none', 'grey'])\n",
    "\n",
    "gridtype = 'ease'\n",
    "gridin = '{}-ease2-050'\n",
    "gridout = '{}-ease2-250'\n",
    "# Overall shape of input grid (4320, 4320)\n",
    "sl = (1050, 1400, 1050, 1400)\n",
    "slo = (200, 290, 200, 290)\n",
    "\n",
    "# EASE plotting region\n",
    "lon_min = -15\n",
    "lon_max = 95\n",
    "lat_min = 74\n",
    "lat_max = 90\n",
    "\n",
    "# Settings for gridlines\n",
    "lon_step = 10\n",
    "lat_step = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72dd220",
   "metadata": {},
   "source": [
    "## Parametrize the run\n",
    "\n",
    "User-set parameters for the running of the whole notebook. Note that here a helper script is used to copy a starter ice concentration file from the MET Norway thredds server and change the dates in this. The date changes are required due to the sample input file here having a date in the future (2028)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1119b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "hemi = 'nh'\n",
    "algos = {'KU': {'channels':('tb19v', 'tb19h'), 'target_band':'KU'},\n",
    "         'KA': {'channels':('tb37v', 'tb37h'), 'target_band':'KA'}}\n",
    "wbs = list(algos.keys())\n",
    "fwdbck = ['fw', 'bk']\n",
    "polarisation = {'V': 0, 'H': 1}\n",
    "pols = list(polarisation.keys())\n",
    "\n",
    "test_card = \"radiometric\"\n",
    "if test_card == \"geometric\":\n",
    "    # DEVALGO's simulated geometric test card\n",
    "    l1bfn = 'W_PT-DME-Lisbon-SAT-CIMR-1B_C_DME_20230417T105425_LD_20280110T114800_20280110T115700_TN.nc'\n",
    "elif test_card == \"radiometric\":\n",
    "    # DEVALGO's simulated radiometric test card\n",
    "    l1bfn = 'W_PT-DME-Lisbon-SAT-CIMR-1B_C_DME_20230420T103323_LD_20280110T114800_20280110T115700_TN.nc'\n",
    "\n",
    "dt = datetime.strptime('20230420T103323', '%Y%m%dT%H%M%S')\n",
    "\n",
    "l1bfile = os.path.join(l1bpath, l1bfn)\n",
    "\n",
    "pdate = datetime.strptime('20280110', '%Y%m%d')\n",
    "tdate = pdate - relativedelta(years=10)\n",
    "qdate = pdate + timedelta(days=1)\n",
    "\n",
    "# Icemask data and output locations\n",
    "icemaskinputdir = 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/{:%Y}/{:%m}'.format(tdate, tdate)\n",
    "icemaskinputfile = 'ice_conc_{}_ease2-250_cdr-v3p0_{:%Y%m%d}1200.nc'.format(hemi, tdate)\n",
    "icemaskinput = cp_and_date_change_iceconc(os.path.join(icemaskinputdir, icemaskinputfile), concpath, pdate)\n",
    "griddeffile = os.path.join(algpath, 'grids_py.def')\n",
    "\n",
    "algo_version = '0.1'\n",
    "\n",
    "plotfigs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b2fbcf",
   "metadata": {},
   "source": [
    "## Step 1: Pre-processing (Icemask, loading the files, Laplacian pre-processing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f7c056",
   "metadata": {},
   "source": [
    "### Step 1a: Creating and regridding the ice mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be5a1e2",
   "metadata": {},
   "source": [
    "A land/ocean/ice mask is required to define the areas with ice to the algorithm. This is created from a concentration file, and is stored for future use. Since there can be multiple ice drift calculations per day on different swaths, the mask can be reused once created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f28fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the ice mask\n",
    "gridname = gridin.format(hemi)\n",
    "icemaskname = os.path.join(icemaskpath, 'icemask-multi-{}-{:%Y%m%d}12.nc'.format(gridname, pdate))\n",
    "if not os.path.isfile(icemaskname):\n",
    "    process_ice_mask(icemaskinput, icemaskpath, griddeffile, gridname)\n",
    "\n",
    "# Reading in the ice mask\n",
    "ie_data = Dataset(icemaskname, 'r')\n",
    "ie = ie_data['ice_edge'][0, :, :]\n",
    "\n",
    "# And the same for the output grid\n",
    "gridnameout = gridout.format(hemi)\n",
    "icemasknameout = os.path.join(icemaskpath, 'icemask-multi-{}-{:%Y%m%d}12.nc'.format(gridnameout, pdate))\n",
    "if not os.path.isfile(icemasknameout):\n",
    "    process_ice_mask(icemaskinput, icemaskpath, griddeffile, gridnameout)\n",
    "ie_data_out = Dataset(icemasknameout, 'r')\n",
    "ieout = ie_data_out['ice_edge'][0, :, :]\n",
    "\n",
    "# Plotting the ice mask\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "c1 = ax1.imshow(ie[:], interpolation = 'none', cmap=cmap)\n",
    "ax1.set_title(\"Ice mask\")\n",
    "ax1.xaxis.set_tick_params(labelbottom=False)\n",
    "ax1.yaxis.set_tick_params(labelleft=False)\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "\n",
    "# Input landmask\n",
    "landmask = np.zeros_like(ie)\n",
    "landmask[ie == 9] = 1\n",
    "\n",
    "# Output landmask\n",
    "landmaskout = np.zeros_like(ieout)\n",
    "landmaskout[ieout == 9] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9360339",
   "metadata": {},
   "source": [
    "### Step 1b: Loading the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569a5f28-1bc5-40e9-b206-438951caa98c",
   "metadata": {},
   "source": [
    "The L1B data is read in and split into forward and backward scans using software from the `Tools/` repository (a prototype CIMR Regridding Toolbox developed in the CIMR DEVALGO study). These forward and backward scans can be used independently in the algorithm in the same way that different channels and polarisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the bands needed of the L1B data\n",
    "reload(io)\n",
    "\n",
    "tb_dict = {'tb01':'L', 'tb06':'C', 'tb10':'X', 'tb19':'KU', 'tb37':'KA'}\n",
    "rev_tb_dict = {v:k for k,v in tb_dict.items()}\n",
    "bands_needed = []\n",
    "for alg in algos.keys():\n",
    "    bands_needed += algos[alg]['channels']\n",
    "bands_needed = list(set([tb_dict[b[:-1]] for b in bands_needed]))\n",
    "\n",
    "full_l1b = io.CIMR_L1B(l1bfile, selected_bands=bands_needed, keep_calibration_view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40457a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into forward / backward scan\n",
    "\n",
    "l1b = {}\n",
    "l1b['fw'], l1b['bk'] = full_l1b.split_forward_backward_scans(method='horn_scan_angle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1874a138",
   "metadata": {},
   "source": [
    "### Step 1c: Regridding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dff9a86",
   "metadata": {},
   "source": [
    "The horns are interleaved, and then the data is regridded. These are again done with software from `Tools/`. The ice drift will be calculated individually on 8 fields based on the forward and backward scans, waveband (Ku or Ka), and polarity (V or H). A fine EASE2 grid spacing of 5km is chosen for this regridding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regridding the data\n",
    "\n",
    "reload(coll)\n",
    "\n",
    "# Reshaping\n",
    "l1b_r = {}\n",
    "for fb in fwdbck:\n",
    "    l1b_r[fb] = l1b[fb].reshape_interleave_feed()\n",
    "\n",
    "# Loading the target grid information\n",
    "gridname = gridin.format(hemi)\n",
    "new_area_def = parse_area_file(griddeffile, gridname)[0]\n",
    "new_lons, new_lats = new_area_def.get_lonlats()\n",
    "\n",
    "# Getting the input lat/lons\n",
    "lonlats = {}\n",
    "for ll in ['lon', 'lat']:\n",
    "    lonlats[ll] = {}\n",
    "    for fb in fwdbck:\n",
    "        lonlats[ll][fb] = {}\n",
    "        for wb in wbs:\n",
    "            lonlats[ll][fb][wb] = l1b_r[fb].data[wb][ll].data\n",
    "\n",
    "# Creating data arrays with the V and H layers\n",
    "what = ('brightness_temperature_v', 'brightness_temperature_h')\n",
    "params = {'method':'gauss', 'sigmas':25000, 'neighbours':55}\n",
    "stack_shape = {}\n",
    "stack = {}\n",
    "regrid = {}\n",
    "for fb in fwdbck:\n",
    "    stack_shape[fb] = {}\n",
    "    stack[fb] = {}\n",
    "    regrid[fb] = {}\n",
    "    for wb in wbs:\n",
    "        stack_shape[fb][wb] = tuple(list(lonlats['lat'][fb][wb].shape) + [len(what),])\n",
    "        stack[fb][wb] = np.empty(stack_shape[fb][wb])\n",
    "        for iw, w in enumerate(what):\n",
    "            stack[fb][wb][...,iw] = l1b_r[fb].data[wb][w].data\n",
    "            # Regridding\n",
    "            # TODO - should params be passed here? With no passing of params, a NN approach with ROI 15000 is used\n",
    "            regrid[fb][wb] = coll._regrid_fields(new_lons, new_lats, \n",
    "                                                 lonlats['lon'][fb][wb], lonlats['lat'][fb][wb], stack[fb][wb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae496fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot regridded\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "ax = {}\n",
    "c = {}\n",
    "shapelayout = (len(fwdbck), len(wbs) * len(pols))\n",
    "axindex = 1\n",
    "for fb in fwdbck:\n",
    "    for wb in wbs:\n",
    "        for pol in pols:\n",
    "            ax[axindex] = fig.add_subplot(*shapelayout, axindex)\n",
    "            c[axindex] = ax[axindex].imshow(regrid[fb][wb][:, :, polarisation[pol]][sl[0]:sl[1], sl[2]:sl[3]], \n",
    "                                            interpolation = 'none', origin='lower', cmap=cmap)\n",
    "            overland = ax[axindex].imshow(landmask[sl[0]:sl[1], sl[2]:sl[3]], interpolation='none',\n",
    "                                          origin='lower', cmap=cmapland)            \n",
    "            ax[axindex].invert_yaxis()\n",
    "            ax[axindex].set_title(\"{} {} {}\".format(wb, pol, fb), fontsize=12)\n",
    "            ax[axindex].xaxis.set_tick_params(labelbottom=False)\n",
    "            ax[axindex].yaxis.set_tick_params(labelleft=False)\n",
    "            ax[axindex].set_xticks([])\n",
    "            ax[axindex].set_yticks([])\n",
    "            axindex += 1\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.25, 0.02, 0.5])\n",
    "fig.colorbar(c[1], cax=cbar_ax, shrink=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f124a3d",
   "metadata": {},
   "source": [
    "# Step 1d: Laplacian pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8965ff33-9712-4fc5-a8ba-d5b1ce47d88c",
   "metadata": {},
   "source": [
    "Instead of directly using the brightness temperatures in the motion tracking algorithm, the ice features are stabilised and enhanced by applying a Laplacian filter (see ATBD for mathmatical description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd9c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian pre-processing\n",
    "\n",
    "from scipy.ndimage import laplace\n",
    "\n",
    "\n",
    "# Replace fill value by NaN and remove mask\n",
    "def _get_nans(img):\n",
    "    img_masked = np.ma.asarray(img)\n",
    "    return img_masked.filled(np.nan)\n",
    "\n",
    "# Replace NaN by fill value and add mask\n",
    "def _mask_nans(img):\n",
    "    return np.ma.masked_invalid(img)\n",
    "\n",
    "nan = {}\n",
    "lap = {}\n",
    "fv = {}\n",
    "for fb in fwdbck:\n",
    "    nan[fb] = {}\n",
    "    lap[fb] = {}\n",
    "    fv[fb] = {}\n",
    "    for wb in wbs:\n",
    "        # Convert fill values to NaNs\n",
    "        nan[fb][wb] = _get_nans(regrid[fb][wb])\n",
    "        # Laplacian transform\n",
    "        lap[fb][wb] = laplace(nan[fb][wb])\n",
    "        # Converting NaNs to fill values\n",
    "        fv[fb][wb] = _mask_nans(lap[fb][wb])\n",
    "\n",
    "# Creating a flag field\n",
    "#define TCIMAGE_OUTSIDE_GRID              -2\n",
    "#define TCIMAGE_NODATA                    -1\n",
    "#define TCIMAGE_OK                         0\n",
    "#define TCIMAGE_UNPROCESSED                1\n",
    "#define TCIMAGE_FAILED                     2\n",
    "flag = {}\n",
    "for fb in fwdbck:\n",
    "    flag[fb] = {}\n",
    "    for wb in wbs:\n",
    "        flag[fb][wb] = np.zeros_like(fv[fb][wb])\n",
    "        # Masking where the Laplacian didn't work\n",
    "        flag[fb][wb][fv[fb][wb].mask] = -1\n",
    "        # Masking where the land and ocean is\n",
    "        landocean = np.logical_or(ie == 9, ie == 1)\n",
    "        flag[fb][wb][landocean] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3257a6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot Laplacian\n",
    "\n",
    "vmin = -100\n",
    "vmax = 100\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "ax = {}\n",
    "c = {}\n",
    "shapelayout = (len(fwdbck), len(wbs) * len(pols))\n",
    "axindex = 1\n",
    "for fb in fwdbck:\n",
    "    for wb in wbs:\n",
    "        for pol in pols:\n",
    "            ax[axindex] = fig.add_subplot(*shapelayout, axindex)\n",
    "            c[axindex] = ax[axindex].imshow(fv[fb][wb][:, :, polarisation[pol]][sl[0]:sl[1], sl[2]:sl[3]], \n",
    "                                            interpolation = 'none', origin='lower', cmap=cmap, \n",
    "                                            vmin=vmin, vmax=vmax)\n",
    "            overland = ax[axindex].imshow(landmask[sl[0]:sl[1], sl[2]:sl[3]], interpolation='none',\n",
    "                                          origin='lower', cmap=cmapland)            \n",
    "            ax[axindex].invert_yaxis()\n",
    "            ax[axindex].set_title(\"{} {} {}\".format(wb, pol, fb), fontsize=12)\n",
    "            ax[axindex].xaxis.set_tick_params(labelbottom=False)\n",
    "            ax[axindex].yaxis.set_tick_params(labelleft=False)\n",
    "            ax[axindex].set_xticks([])\n",
    "            ax[axindex].set_yticks([])\n",
    "            axindex += 1\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.25, 0.02, 0.5])\n",
    "fig.colorbar(c[1], cax=cbar_ax, shrink=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f5251",
   "metadata": {},
   "source": [
    "# Step 1e: Writing out the file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa647d9c",
   "metadata": {},
   "source": [
    "For ice drift, it is not possible to keep the data only internally. Since two gridded files at different timepoints are required to create each gridded map of icedrift vectors, it is necessary to write each gridded swath file to disk so that it can be read in to be compared with other gridded swath files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b47b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: It is deprecated, but the wrapper and C code still expect a input prog4_string, so accept the deprecation warning for now.\n",
    "crs_info = {'proj4_string': new_area_def.proj4_string,\n",
    "             'area_id': new_area_def.area_id,\n",
    "             'semi_major_axis': 6378137.,\n",
    "             'semi_minor_axis': 6356752.31424518,\n",
    "             'inverse_flattening': 298.257223563,\n",
    "             'reference_ellipsoid_name': \"WGS 84\",\n",
    "             'longitude_of_prime_meridian': 0.,\n",
    "             'prime_meridian_name': \"Greenwich\",\n",
    "             'geographic_crs_name': \"unknown\",\n",
    "             'horizontal_datum_name': \"World Geodetic System 1984\",\n",
    "             'projected_crs_name': \"unknown\",\n",
    "             'grid_mapping_name': \"lambert_azimuthal_equal_area\",\n",
    "             'latitude_of_projection_origin': 90.,\n",
    "             'longitude_of_projection_origin': 0.,\n",
    "             'false_easting': 0.,\n",
    "             'false_northing': 0.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(l2)\n",
    "\n",
    "# Get a template L2 format (netCDF/CF) from the Tools module\n",
    "ds_l2 = l2.get_CIMR_L2_template('grid', geo_def=new_area_def, add_time=[pdate.timestamp()])\n",
    "\n",
    "# Create data arrays for the brightness temperatures, laplacian processed and status flags from the template\n",
    "shp = (1, *regrid[fwdbck[0]][wbs[0]][:, :, polarisation[pol]].shape)\n",
    "ds_tb = {}\n",
    "ds_lap = {}\n",
    "ds_flag = {}\n",
    "for fb in fwdbck:\n",
    "    ds_tb[fb] = {}\n",
    "    ds_lap[fb] = {}\n",
    "    ds_flag[fb] = {}\n",
    "    for wb in wbs:\n",
    "        ds_tb[fb][wb] = {}\n",
    "        ds_lap[fb][wb] = {}\n",
    "        ds_flag[fb][wb] = {}\n",
    "        for pol in pols:\n",
    "            chan = algos[wb]['channels'][polarisation[pol]]\n",
    "            ds_tb[fb][wb][pol] = xr.DataArray(regrid[fb][wb][:, :, polarisation[pol]].reshape(shp),\n",
    "                                              coords=ds_l2['template'].coords, dims=ds_l2['template'].dims,\n",
    "                                              attrs=ds_l2['template'].attrs, name='{}{}'.format(chan, fb))\n",
    "            ds_tb[fb][wb][pol].attrs['standard_name'] = 'brightness_temperature'\n",
    "            ds_tb[fb][wb][pol].attrs['long_name'] = 'Brightness temperature {}'.format(chan, fb)\n",
    "            ds_tb[fb][wb][pol].attrs['coverage_content_type'] = 'physicalMeasurement'\n",
    "            ds_tb[fb][wb][pol].attrs['units'] = 'K'\n",
    "            ds_l2 = ds_l2.merge(ds_tb[fb][wb][pol])\n",
    "            \n",
    "            ds_lap[fb][wb][pol] = xr.DataArray(fv[fb][wb][:, :, polarisation[pol]].reshape(shp),\n",
    "                                               coords=ds_l2['template'].coords, dims=ds_l2['template'].dims,\n",
    "                                               attrs=ds_l2['template'].attrs, name='{}{}_lap'.format(chan, fb))\n",
    "            ds_lap[fb][wb][pol].attrs['long_name'] = 'Laplacian of brightness temperature {}'.format(chan, fb)\n",
    "            ds_lap[fb][wb][pol].attrs['coverage_content_type'] = 'auxiliaryInformation'\n",
    "            ds_lap[fb][wb][pol].attrs['units'] = 1\n",
    "            ds_l2 = ds_l2.merge(ds_lap[fb][wb][pol])\n",
    "            \n",
    "            ds_flag[fb][wb][pol] = xr.DataArray(flag[fb][wb][:, :, polarisation[pol]].reshape(shp),\n",
    "                                                coords=ds_l2['template'].coords, dims=ds_l2['template'].dims,\n",
    "                                                attrs=ds_l2['template'].attrs, \n",
    "                                                name='{}{}_lap_flag'.format(chan, fb))\n",
    "            ds_flag[fb][wb][pol].attrs['standard_name'] = 'status_flag'\n",
    "            ds_flag[fb][wb][pol].attrs['long_name'] = 'Status flag for Laplacian of brightness temperature {}'.format(chan, fb)\n",
    "            ds_flag[fb][wb][pol].attrs['coverage_content_type'] = 'qualityInformation'\n",
    "            ds_flag[fb][wb][pol].attrs['units'] = 1\n",
    "            ds_l2 = ds_l2.merge(ds_flag[fb][wb][pol])\n",
    "\n",
    "# Create a data array for dtime from the template\n",
    "dtime = np.full_like(regrid[fwdbck[0]][wbs[0]][:, :, 0], pdate.timestamp()).reshape(shp)\n",
    "ds_dtime = xr.DataArray(dtime, coords=ds_l2['template'].coords, dims=ds_l2['template'].dims,\n",
    "                        attrs=ds_l2['template'].attrs, name='dtime')\n",
    "ds_dtime.attrs['long_name'] = 'Time'\n",
    "ds_dtime.attrs['standard_name'] = 'time'\n",
    "ds_dtime.attrs['coverage_content_type'] = 'auxiliaryInformation'\n",
    "ds_dtime.attrs['units'] = 'seconds since 1970-01-01 00:00:00'\n",
    "ds_l2 = ds_l2.merge(ds_dtime)\n",
    "\n",
    "# Create a data array for ice edge from the template\n",
    "ds_ie = xr.DataArray(ie.reshape(shp), coords=ds_l2['template'].coords, dims=ds_l2['template'].dims,\n",
    "                     attrs=ds_l2['template'].attrs, name='ice_edge')\n",
    "ds_ie.attrs['long_name'] = 'Ice edge'\n",
    "ds_ie.attrs['coverage_content_type'] = 'auxiliaryInformation'\n",
    "ds_ie.attrs['units'] = 1\n",
    "ds_l2 = ds_l2.merge(ds_ie)\n",
    "\n",
    "# Create a data array for time, needed by the C code\n",
    "timedata = np.full_like(regrid[fb][wb][0, 0, 0], pdate.timestamp())\n",
    "ds_l2['vtime'] = (('time'), timedata.reshape(1,))\n",
    "ds_l2['time'].attrs = {'units': \"seconds since 1970-01-01 00:00:00\"}\n",
    "ds_l2.attrs['long_name'] = 'Time'\n",
    "ds_l2.attrs['coverage_content_type'] = 'auxiliaryInformation'\n",
    "ds_l2.attrs['units'] = \"seconds since 1970-01-01 00:00:00\"\n",
    "\n",
    "# Customize the global attributes\n",
    "ds_l2.attrs['title'] = 'CIMR intermediate brightness temperatures for ice drift calculation'\n",
    "ds_l2.attrs['summary'] = 'Intermediate brightness temperatures and Laplacian-processed fields with their status flags, written as intermadiate-processing file for ice drift calculations'\n",
    "ds_l2.attrs['l1b_file'] = l1bfn\n",
    "ds_l2.attrs['algorithm_version'] = algo_version\n",
    "ds_l2.attrs['creator_name'] = 'Emily Down'\n",
    "ds_l2.attrs['creator_email'] = 'emilyjd@met.no'\n",
    "ds_l2.attrs['institution'] = 'Norwegian Meteorological Institute'\n",
    "\n",
    "# CRS information needed for C code\n",
    "ds_l2['crs'].attrs = crs_info\n",
    "\n",
    "# Need to rename x and y to xc and yc for X code\n",
    "ds_l2= ds_l2.rename({'x': 'xc','y': 'yc'})\n",
    "    \n",
    "# Remove the 'template' variable (we don't need it anymore)\n",
    "#ds_l2 = ds_l2.drop('template')\n",
    "\n",
    "# Write to file\n",
    "dsname = os.path.join(procpath, 'bt_{}_{:%Y%m%d}.nc'.format(gridname, pdate))\n",
    "ds_l2.to_netcdf(dsname, 'w', format=\"NETCDF4_CLASSIC\")\n",
    "print(\"Written {}\".format(dsname))\n",
    "\n",
    "# Setting this up for potential reruns\n",
    "ds_l2_copy = ds_l2.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3575fa19",
   "metadata": {},
   "source": [
    "### Step 1f (temporary): Creating a test gridded file with \"time difference\" 24h and 1 px added in each x and y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba69c246-b3fa-43b3-845c-a095ef9767ca",
   "metadata": {},
   "source": [
    "This is a temporary part of this notebook, to create a \"test\" file with different gridded brightness temperatures and a different timepoint. This is required for calculation of ice drift vectors. In this example, a constant shift of +3 pixels in the x-direction and +4 pixels in the y-direction is chosen. In operation, two swaths at different timepoints will be processed in the algorithm to retrieve the icedrift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b994706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a shifted file. These are the pixel shifts\n",
    "pixshx = 3\n",
    "pixshy = 4\n",
    "\n",
    "# Take a copy of the data xarray\n",
    "ds_shift = ds_l2_copy.copy()\n",
    "\n",
    "# Add the Laplacian mask variable\n",
    "ds_msk = {}\n",
    "ds_msk = {}\n",
    "ds_msk = {}\n",
    "for fb in fwdbck:\n",
    "    ds_msk[fb] = {}\n",
    "    for wb in wbs:\n",
    "        ds_msk[fb][wb] = {}\n",
    "        for pol in pols:\n",
    "            chan = algos[wb]['channels'][polarisation[pol]]\n",
    "            ds_msk[fb][wb][pol] = xr.DataArray(fv[fb][wb][:, :, polarisation[pol]].mask.reshape(shp),\n",
    "                                               coords=ds_shift['template'].coords, dims=ds_shift['template'].dims,\n",
    "                                               attrs=ds_shift['template'].attrs, name='{}{}_msk'.format(chan, fb))\n",
    "            ds_msk[fb][wb][pol].attrs['long_name'] = 'Mask for Laplacian of brightness temperature {}'.format(chan, fb)\n",
    "            ds_msk[fb][wb][pol].attrs['coverage_content_type'] = 'auxiliaryInformation'\n",
    "            ds_msk[fb][wb][pol].attrs['units'] = 1\n",
    "            ds_shift = ds_shift.merge(ds_msk[fb][wb][pol])\n",
    "\n",
    "# Shifting the data pixels of the arrays\n",
    "ds_shift_tb = {}\n",
    "ds_shift_lap = {}\n",
    "ds_shift_flag = {}\n",
    "for fb in fwdbck:\n",
    "    ds_shift_tb[fb] = {}\n",
    "    ds_shift_lap[fb] = {}\n",
    "    ds_shift_flag[fb] = {}\n",
    "    for wb in wbs:\n",
    "        ds_shift_tb[fb][wb] = {}\n",
    "        ds_shift_lap[fb][wb] = {}\n",
    "        ds_shift_flag[fb][wb] = {}\n",
    "        for pol in pols:\n",
    "            chan = algos[wb]['channels'][polarisation[pol]]\n",
    "            # Shift can be used in xarray to shift dimension by number of pix. Note that the dimensions must be\n",
    "            # called x and y within xarray\n",
    "            chan = algos[wb]['channels'][polarisation[pol]]\n",
    "            tbname = '{}{}'.format(chan, fb)\n",
    "            ds_shift_tb[fb][wb] = ds_shift.get(tbname).shift(xc=pixshx, yc=pixshy)\n",
    "            ds_shift[tbname].data = ds_shift_tb[fb][wb]\n",
    "            # Shifting the Laplacian field\n",
    "            lapname = '{}{}_lap'.format(chan, fb)\n",
    "            ds_shift_lap[fb][wb] = ds_shift.get(lapname).shift(xc=pixshx, yc=pixshy)\n",
    "            ds_shift[lapname].data = ds_shift_lap[fb][wb]\n",
    "            # Flag field (want the data shifted, the landmask not)  \n",
    "            flagname = '{}{}_lap_flag'.format(chan, fb)\n",
    "            ds_shift_flag[fb][wb] = np.zeros_like(ds_shift_lap[fb][wb])\n",
    "            # Masking where the Laplacian failed\n",
    "            maskname = '{}{}_msk'.format(chan, fb)\n",
    "            fmsk_shft = ds_shift.get(maskname).shift(xc=pixshx, yc=pixshy)\n",
    "            ds_shift_flag[fb][wb][fmsk_shft == 1] = -1\n",
    "            # Masking where the land and ocean is\n",
    "            landocean = np.logical_or(ie == 9, ie == 1).reshape(shp)\n",
    "            (ds_shift_flag[fb][wb])[landocean] = 1\n",
    "            ds_shift[flagname].data = ds_shift_flag[fb][wb]\n",
    "\n",
    "# Shift time by 24h\n",
    "ds_shift['dtime'].data = np.full_like(regrid[fwdbck[0]][wbs[0]][:, :, 0], qdate.timestamp()).reshape(shp)\n",
    "ds_shift.assign_coords(time = [qdate.timestamp()])\n",
    "\n",
    "# Remove the mask variables (we don't need them anymore)\n",
    "for fb in fwdbck:\n",
    "    for wb in wbs:\n",
    "        for pol in pols:\n",
    "            chan = algos[wb]['channels'][polarisation[pol]]\n",
    "            maskname = '{}{}_msk'.format(chan, fb)\n",
    "            ds_shift = ds_shift.drop_vars(maskname)\n",
    "\n",
    "# Write to file\n",
    "dsname2 = os.path.join(procpath, 'bt_{}_{:%Y%m%d}.nc'.format(gridname, qdate))\n",
    "ds_shift.to_netcdf(dsname2, 'w', format=\"NETCDF4_CLASSIC\")\n",
    "print(\"Written {}\".format(dsname2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c30e3e7",
   "metadata": {},
   "source": [
    "## Step 2: Cross-correlation algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f2dec2",
   "metadata": {},
   "source": [
    "For the Continuous Maximum Cross-Correlation algorithm, two brightness temperature gridded files, enhanced by the Laplacian algorithm and with different timestamps, are required. The algorithm matches features between these images on a fractional pixel grid.\n",
    "\n",
    "The steps of the cross-correlation algorithm are:\n",
    "1. Determination of which pixels should be included in the cross-correlation, excluding land and ocean pixels.\n",
    "2. Fractional pixel cross-correlation simultaneously on the gridded swaths - forward/back scans, V and H polarisations, Ku and Ka channels.\n",
    "3. Correction of erroneous vectors using the nearest neighbour method and creation of status flags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188b04d",
   "metadata": {},
   "source": [
    "### Step 2a: Run the cross-correlation algorithm to find the ice drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd99e5be-5c41-43b4-8fe2-28a69a3f5681",
   "metadata": {},
   "source": [
    "Currently the C code has limited memory for channels, so the forward and backward scans with V and H polarisations are accepted by the code. It should be possible to add Ka-band later. \n",
    "\n",
    "In addition, the forward and backward scans are treated here as having the same timestamp, later it can be refined to include the 7-minute delay between these two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365120c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying the files with new names, to interface with the C-code\n",
    "\n",
    "chanstr = 'tb19hfw-tb19vfw-tb19hbk-tb19vbk-tb37hfw-tb37vfw-tb37hbk-tb37vbk'\n",
    "newname1 = 'tc_wght_cimr-cimr_{}_{}_{}12.nc'.format(chanstr, gridin.format(hemi), datetime.strftime(pdate, '%Y%m%d'))\n",
    "newname2 = 'tc_wght_cimr-cimr_{}_{}_{}12.nc'.format(chanstr, gridin.format(hemi), datetime.strftime(qdate, '%Y%m%d'))\n",
    "shutil.copyfile(dsname, os.path.join(os.path.dirname(dsname), newname1))\n",
    "shutil.copyfile(dsname2, os.path.join(os.path.dirname(dsname), newname2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8db6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from icedrift_wrapper import icedrift_wrapper\n",
    "rad = 100.\n",
    "rad_neigh = 150.\n",
    "# Original rad=75. rad_neigh=125.\n",
    "# Worked with rad=100. rad_neigh=150.\n",
    "# rad = 25. rad_neigh=150. has lots of corrected by neighbours, but a better field\n",
    "chan_list = ['tb37hfw_lap', 'tb37vfw_lap', 'tb37hbk_lap', 'tb37vbk_lap']\n",
    "idrift = icedrift_wrapper(pdate, qdate, procpath, procpath, driftpath, os.path.join(logpath, 'cmcc-test.log'),\n",
    "                          'cimr-cimr', gridin.format(hemi), chan_list, rad, rad_neigh, \n",
    "                          area_out=gridout.format(hemi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709ab594",
   "metadata": {},
   "source": [
    "### Step 2b: Format L2 file and write to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fad231-6d85-4f18-ac24-05b14278d88c",
   "metadata": {},
   "source": [
    "The output icedrift file is processed and written, with metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e310f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driftx = ma.asarray(idrift['drift_x'])\n",
    "driftx.mask = driftx < -1e9\n",
    "drifty = ma.asarray(idrift['drift_y'])\n",
    "drifty.mask = drifty < -1e9\n",
    "flag = ma.asarray(idrift['flag'])\n",
    "\n",
    "dms = driftx.shape\n",
    "ddx = driftx.reshape(1, dms[0], dms[1])\n",
    "ddy = drifty.reshape(1, dms[0], dms[1])\n",
    "stdx = ma.asarray(idrift['std_x'])\n",
    "stdx.mask = stdx < -1e9\n",
    "stdx = stdx.reshape(1, dms[0], dms[1])\n",
    "stdy = ma.asarray(idrift['std_y'])\n",
    "stdy.mask = stdy < -1e9\n",
    "stdy = stdy.reshape(1, dms[0], dms[1])\n",
    "dflag = ma.asarray(idrift['flag'])\n",
    "dflag = flag.reshape(1, dms[0], dms[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5292793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(l2)\n",
    "\n",
    "# Output grid\n",
    "og = gridout.format(hemi)\n",
    "out_area_def = parse_area_file(griddeffile, og)[0]\n",
    "olons, olats = out_area_def.get_lonlats()\n",
    "\n",
    "# Get a template L2 format (netCDF/CF) from the Tools module\n",
    "ds_l2 = l2.get_CIMR_L2_template('grid', geo_def=out_area_def, add_time=[pdate.timestamp()])\n",
    "\n",
    "# Create a DataArray for x and y icedrift from the template\n",
    "da_dx = xr.DataArray(ddx, coords=ds_l2['template'].coords, dims=ds_l2['template'].dims,\n",
    "                       attrs=ds_l2['template'].attrs, name='driftX')\n",
    "da_dx.attrs['long_name'] = 'x-component of Sea Ice Drift from the CIMR ice drift algorithm v{}'.format(algo_version)\n",
    "da_dx.attrs['standard_name'] = 'x_component_sea_ice_drift'\n",
    "da_dx.attrs['units'] = 'km'\n",
    "da_dx.attrs['coverage_content_type'] = 'physicalMeasurement'\n",
    "da_dx.attrs['auxiliary_variables'] = 'status_flag'\n",
    "da_dy = xr.DataArray(ddy, coords=ds_l2['template'].coords, dims=ds_l2['template'].dims,\n",
    "                       attrs=ds_l2['template'].attrs, name='driftY')\n",
    "da_dy.attrs['long_name'] = 'y-component of Sea Ice Drift from the CIMR ice drift algorithm v{}'.format(algo_version)\n",
    "da_dy.attrs['standard_name'] = 'y_component_sea_ice_drift'\n",
    "da_dy.attrs['units'] = 'km'\n",
    "da_dy.attrs['coverage_content_type'] = 'physicalMeasurement'\n",
    "da_dy.attrs['auxiliary_variables'] = 'status_flag'\n",
    "\n",
    "# Create a DataArray for std x and y icedrift from the template\n",
    "da_stddx = xr.DataArray(stdx, coords=ds_l2['template'].coords, dims=ds_l2['template'].dims,\n",
    "                       attrs=ds_l2['template'].attrs, name='stdX')\n",
    "da_stddx.attrs['long_name'] = 'Standard deviation of x-component of Sea Ice Drift from the CIMR ice drift algorithm v{}'.format(algo_version)\n",
    "da_stddx.attrs['units'] = 'km'\n",
    "da_stddx.attrs['coverage_content_type'] = 'auxiliaryInformation'\n",
    "da_stddx.attrs['auxiliary_variables'] = 'status_flag'\n",
    "da_stddy = xr.DataArray(stdy, coords=ds_l2['template'].coords, dims=ds_l2['template'].dims,\n",
    "                       attrs=ds_l2['template'].attrs, name='stdY')\n",
    "da_stddy.attrs['long_name'] = 'Standard deviation of y-component of Sea Ice Drift from the CIMR ice drift algorithm v{}'.format(algo_version)\n",
    "da_stddy.attrs['units'] = 'km'\n",
    "da_stddy.attrs['coverage_content_type'] = 'auxiliaryInformation'\n",
    "da_stddy.attrs['auxiliary_variables'] = 'status_flag'\n",
    "\n",
    "# Create a DataArray for the status flag from the template\n",
    "da_flag = xr.DataArray(dflag, coords=ds_l2['template'].coords, dims=ds_l2['template'].dims,\n",
    "                       attrs=ds_l2['template'].attrs, name='status_flag')\n",
    "da_flag.attrs['long_name'] = 'Status flag of Sea Ice Drift from the CIMR ice drift algorithm v{}'.format(algo_version)\n",
    "da_flag.attrs['units'] = 1\n",
    "da_flag.attrs['coverage_content_type'] = 'auxiliaryInformation'\n",
    "\n",
    "# Add the data arrays to the ds_l2 object\n",
    "ds_l2 = ds_l2.merge(da_dx)\n",
    "ds_l2 = ds_l2.merge(da_dy)\n",
    "ds_l2 = ds_l2.merge(da_stddx)\n",
    "ds_l2 = ds_l2.merge(da_stddy)\n",
    "ds_l2 = ds_l2.merge(da_flag)\n",
    "\n",
    "# Customize the global attributes\n",
    "ds_l2.attrs['title'] = 'CIMR L2 Sea Ice Drift'\n",
    "ds_l2.attrs['summary'] = 'Sea Ice Drift computed with the prototype algorithm developed in the ESA CIMR DEVALGO study. The algorithm combines Ku and Ka imagery channels. The product file contains the sea ice drift, its uncertainties, and processing flags.'\n",
    "ds_l2.attrs['l1b_file'] = os.path.basename(l1bfile)\n",
    "ds_l2.attrs['algorithm_version'] = algo_version\n",
    "\n",
    "ds_l2.attrs['creator_name'] = 'Emily Down and Thomas Lavergne'\n",
    "ds_l2.attrs['creator_email'] = 'emilyjd@met.no'\n",
    "ds_l2.attrs['institution'] = 'Norwegian Meteorological Institute'\n",
    "\n",
    "# Remove the 'template' variable (we don't need it anymore)\n",
    "ds_l2 = ds_l2.drop_vars('template')\n",
    "\n",
    "# Write to file\n",
    "l2_n = 'cimr_devalgo_l2_sid_{}_{}.nc'.format(og, test_card)\n",
    "l2_n = os.path.join(driftpath, l2_n)\n",
    "ds_l2.to_netcdf(l2_n, format='NETCDF4_CLASSIC')\n",
    "print(l2_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4884a5f5",
   "metadata": {},
   "source": [
    "### Step 2c: Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3dbf84-a470-490d-953c-4e3706a84060",
   "metadata": {},
   "source": [
    "Here an example plot of the icedrift output is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd282cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crs_create(gridtype, hemi):\n",
    "\n",
    "    # Define grid based on region\n",
    "    if gridtype == 'polstere':\n",
    "        if hemi == 'nh':\n",
    "            plot_proj4_params = {'proj': 'stere',\n",
    "                                 'lat_0': 90.,\n",
    "                                 'lat_ts' : 70.,\n",
    "                                 'lon_0': -45.0,\n",
    "                                 'a': 6378273,\n",
    "                                 'b': 6356889.44891}\n",
    "            plot_globe = ccrs.Globe(semimajor_axis=plot_proj4_params['a'],\n",
    "                                    semiminor_axis=plot_proj4_params['b'])\n",
    "            plot_crs = ccrs.NorthPolarStereo(\n",
    "                central_longitude=plot_proj4_params['lon_0'], globe=plot_globe)\n",
    "        else:\n",
    "            plot_proj4_params = {'proj': 'stere',\n",
    "                                 'lat_0': -90.,\n",
    "                                 'lat_ts' : -70.,\n",
    "                                 'lon_0': 0.,\n",
    "                                 'a': 6378273,\n",
    "                                 'b': 6356889.44891}\n",
    "            plot_globe = ccrs.Globe(semimajor_axis=plot_proj4_params['a'],\n",
    "                                    semiminor_axis=plot_proj4_params['b'])\n",
    "            plot_crs = ccrs.SouthPolarStereo(\n",
    "                central_longitude=plot_proj4_params['lon_0'], globe=plot_globe)\n",
    "    elif gridtype == 'ease':\n",
    "        if hemi == 'nh':\n",
    "            plot_crs = ccrs.LambertAzimuthalEqualArea(central_longitude=0,\n",
    "                                                      central_latitude=90,\n",
    "                                                      false_easting=0,\n",
    "                                                      false_northing=0)\n",
    "        else:\n",
    "            plot_crs = ccrs.LambertAzimuthalEqualArea(central_longitude=0,\n",
    "                                                      central_latitude=-90,\n",
    "                                                      false_easting=0,\n",
    "                                                      false_northing=0)\n",
    "    else:\n",
    "        raise ValueError(\"Unrecognised region {}\".format(region))\n",
    "\n",
    "    return(plot_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c7601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_arrow_col(flag, procfmt=False):\n",
    "\n",
    "    if procfmt:\n",
    "        flgfmt = 'proc'\n",
    "    else:\n",
    "        flgfmt = 'final'\n",
    "\n",
    "    # Use colours from https://sashamaps.net/docs/resources/20-colors/\n",
    "    fblack = '#000000'\n",
    "    fmaroon = '#800000'\n",
    "    forange = '#f58231'\n",
    "    fnavy = '#000075'\n",
    "    fblue = '#4363d8'\n",
    "    flavender = '#dcbeff'\n",
    "    fgrey = '#a9a9a9'\n",
    "\n",
    "    fbrown = '#9A6324'\n",
    "    fteal = '#469990'\n",
    "    fgreen = '#3cb44b'\n",
    "    fcyan = '#42d4f4'\n",
    "    fmagenta = '#f032e6'\n",
    "\n",
    "    fred = '#e6194B'\n",
    "    fpurple = '#911eb4'\n",
    "\n",
    "    flag_cols = {}\n",
    "    flag_cols['final'] = {30: fblack,   # Nominal quality\n",
    "                          20: fbrown,   # Single-sensor, with smaller pattern\n",
    "                                        # block\n",
    "                          21: forange,  # Single-sensor, with neighbours as\n",
    "                                        # constraint\n",
    "                          22: fmaroon,  # Interpolated\n",
    "                          23: fcyan,    # Gap filling in wind drift\n",
    "                          24: fteal,    # Vector replaced by wind drift\n",
    "                          25: fnavy,    # Blended satellite and wind drift\n",
    "}\n",
    "    flag_cols['proc'] = {0: fblack,     # Nominal quality\n",
    "                         16: fpurple,   # Interpolated\n",
    "                         13: fred,      # Single-sensor, with neighbours as\n",
    "                                        # constraint\n",
    "                         17: fgreen,    # Single-sensor, with smaller\n",
    "                                        # pattern block\n",
    "}\n",
    "\n",
    "    default = 'black'\n",
    "    if flag in flag_cols[flgfmt].keys():\n",
    "        return flag_cols[flgfmt][flag]\n",
    "    else:\n",
    "        #print(\"WARNING: unsupported flag value {}. Default to {}.\"\n",
    "        #      \"\".format(flag, default))\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53a2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 1000.\n",
    "pc = ccrs.PlateCarree()\n",
    "#print(\"pc = \", pc)\n",
    "\n",
    "def plotdriftarr(ax, plot_crs, data_crs, lon, lat, dx, dy, sflag, driftflags=True):\n",
    "    \n",
    "    for i in range(dx.size):\n",
    "        try:\n",
    "            x0, y0 = plot_crs.transform_point(lon[~dx.mask][i], lat[~dx.mask][i], src_crs=pc)\n",
    "            adx = dx[~dx.mask][i]\n",
    "            ady = dy[~dy.mask][i]\n",
    "            len_arrow = math.sqrt(adx**2 + ady**2)\n",
    "\n",
    "            # Calculate the endpoints and therefore dx, dy components of the drift arrows in the plot\n",
    "            # coordinate system\n",
    "            xorig, yorig = data_crs.transform_point(lon[~dx.mask][i], lat[~dx.mask][i], src_crs=pc)\n",
    "            xarr = xorig + adx\n",
    "            yarr = yorig + ady\n",
    "            x1, y1 = plot_crs.transform_point(xarr, yarr, src_crs=data_crs)\n",
    "            pdx = (x1 - x0) * scale\n",
    "            pdy = (y1 - y0) * scale\n",
    "            \n",
    "            # Set the colour of the drift arrows if this should be\n",
    "            # done with status flags\n",
    "            if driftflags:\n",
    "                myflag = sflag[~dx.mask][i]\n",
    "                ar_col = flag_arrow_col(myflag, procfmt=True)\n",
    "            else:\n",
    "                ar_col = 'black'\n",
    "\n",
    "            # If the arrow is too small, mark a symbol instead\n",
    "            if len_arrow * scale < 2000:\n",
    "                plt.plot(x0, y0, 's', color=ar_col, markersize=1)\n",
    "            else:\n",
    "                head_length = 0.3 * len_arrow * scale\n",
    "                plt.arrow(x0, y0, pdx, pdy, color=ar_col,\n",
    "                    shape='full', head_length=head_length,\n",
    "                    head_width=15000,\n",
    "                    fill=True, length_includes_head=True,\n",
    "                    width=4000)\n",
    "\n",
    "        except:\n",
    "            pass # Outside the range of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a008d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the ice drift with arrows\n",
    "# Modified from the SeaSurfaceTemperature_ATBD_v2, by Emy Alerskans\n",
    "\n",
    "# Drift data\n",
    "xydata = {'dx': driftx, 'dy': drifty}\n",
    "limminxy = np.nanmin([np.nanmin(a) for a in xydata.values()])\n",
    "limminxy = limminxy - 0.1 * abs(limminxy)\n",
    "limmaxxy = np.nanmax([np.nanmax(a) for a in xydata.values()])\n",
    "limmaxxy = limmaxxy + 0.1 * abs(limmaxxy)\n",
    "limminflag = np.nanmin(flag)\n",
    "limmaxflag = np.nanmax(flag)\n",
    "\n",
    "# Output lat/lons\n",
    "og = gridout.format(hemi)\n",
    "out_area_def = parse_area_file(griddeffile, og)[0]\n",
    "olons, olats = out_area_def.get_lonlats()\n",
    "\n",
    "# Coordinate reference systems\n",
    "plot_crs = crs_create(gridtype, hemi)\n",
    "pc = ccrs.PlateCarree()\n",
    "if 'ease' in gridout:\n",
    "    data_crs = crs_create('ease', hemi)\n",
    "else:\n",
    "    data_crs = crs_create('polstere', hemi)\n",
    "\n",
    "# Plotting drift\n",
    "fig = plt.figure(figsize=[12, 10])\n",
    "ax = fig.add_subplot(1, 1, 1, projection=plot_crs)\n",
    "\n",
    "plotdriftarr(ax, plot_crs, data_crs, olons[slo[0]:slo[1], slo[2]:slo[3]], olats[slo[0]:slo[1], slo[2]:slo[3]], \n",
    "             driftx[slo[0]:slo[1], slo[2]:slo[3]], drifty[slo[0]:slo[1], slo[2]:slo[3]],\n",
    "             flag[slo[0]:slo[1], slo[2]:slo[3]], driftflags=True)\n",
    "\n",
    "ax.coastlines()\n",
    "ax.set_extent([lon_min, lon_max, lat_min, lat_max])\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, linewidth=1, color='k', alpha=0.5, linestyle=':')\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xlocator = mticker.FixedLocator(np.arange(-180, 180, lon_step))\n",
    "gl.ylocator = mticker.FixedLocator(np.arange(-90, 90, lat_step))\n",
    "gl.xlabel_style = {'size': 14}\n",
    "gl.ylabel_style = {'size': 14}    \n",
    "\n",
    "# Status flags\n",
    "fig = plt.figure(figsize=[12, 10])\n",
    "ax = fig.add_subplot(1, 1, 1, projection=plot_crs)\n",
    "im = ax.pcolormesh(olons[slo[0]:slo[1], slo[2]:slo[3]], olats[slo[0]:slo[1], slo[2]:slo[3]], \n",
    "                    flag[:][slo[0]:slo[1], slo[2]:slo[3]], transform=pc,\n",
    "                    cmap=cmap, vmin=limminflag, vmax=limmaxflag)\n",
    "ax.coastlines()\n",
    "ax.set_extent([lon_min, lon_max, lat_min, lat_max])\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, linewidth=1, color='k', alpha=0.5, linestyle=':')\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xlocator = mticker.FixedLocator(np.arange(-180, 180, lon_step))\n",
    "gl.ylocator = mticker.FixedLocator(np.arange(-90, 90, lat_step))\n",
    "gl.xlabel_style = {'size': 14}\n",
    "gl.ylabel_style = {'size': 14}\n",
    "        \n",
    "# Colourbar\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"3%\", pad=\"2%\", axes_class=plt.Axes)\n",
    "cb = fig.colorbar(im, cax=cax)\n",
    "cb.set_label(label=\"Flag\", fontsize=16, labelpad=20.0)\n",
    "cb.ax.set_ylim(limminflag, limmaxflag)\n",
    "        \n",
    "if plotfigs:\n",
    "    plt.savefig(os.path.join(figpath, 'drift_rad{}.png'.format(int(rad))))\n",
    "plt.show()\n",
    "\n",
    "print(\"\\\n",
    "FLAG VALUES \\n\\\n",
    "Unprocessed pixel                              -1\\n\\\n",
    "Nominal                                        0\\n\\\n",
    "Outside image border                           1\\n\\\n",
    "Close to image border                          2\\n\\\n",
    "Pixel center over land                         3\\n\\\n",
    "No ice                                         4\\n\\\n",
    "Close to coast or edge                         5\\n\\\n",
    "Close to missing pixel                         6\\n\\\n",
    "Close to unprocessed pixel                     7\\n\\\n",
    "Icedrift optimisation failed                   8\\n\\\n",
    "Icedrift failed                                9\\n\\\n",
    "Icedrift with low correlation                  10\\n\\\n",
    "Icedrift calculation took too long             11\\n\\\n",
    "Icedrift calculation refused by neighbours     12\\n\\\n",
    "Icedrift calculation corrected by neighbours   13\\n\\\n",
    "Icedrift no average                            14\\n\\\n",
    "Icedrift masked due to summer season           15\\n\\\n",
    "Icedrift multi-oi interpolation                16\\n\\\n",
    "Icedrift calcuated with smaller pattern        17\\n\\\n",
    "Icedrift masked due to NWP                     18\\n\\\n",
    "\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
